{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb00e1ec",
   "metadata": {},
   "source": [
    "**PREPROCESSING WITH PRE-FOG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47a0ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prefog(dataset,window_length = 1):\n",
    "  dataset.drop(index = list(dataset[dataset['Action'] == 0].index),inplace=True)\n",
    "  window_length = 64*window_length\n",
    "    \n",
    "  fog_index=[]\n",
    "  for i in dataset.index: \n",
    "      if dataset.loc[i,'Action'] == 2:\n",
    "        fog_index.append(i)\n",
    "  fog_index\n",
    "\n",
    "  start_indices=[]\n",
    "  for i in fog_index:\n",
    "    if (dataset.loc[i-1,'Action']!=dataset.loc[i,'Action']):\n",
    "      start_indices.append(i)\n",
    " \n",
    "\n",
    "  prefog=[]\n",
    "  for start in start_indices:\n",
    "    prefog_start = [x for x in range(start-window_length,start)]\n",
    "    prefog.append(prefog_start)\n",
    "\n",
    "  prefog = [item for sublist in prefog for item in sublist]\n",
    "\n",
    "  for i in prefog:\n",
    "       dataset.loc[i,'Action'] = 3\n",
    "  dataset['Action'] = dataset['Action'] - 1\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29ad8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/ashwin/Documents/Ashwin/Bright Academy/Research/dataset_fog_release/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfff5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c4c8f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S10R01.txt',\n",
       " 'S02R01.txt',\n",
       " 'S02R02.txt',\n",
       " 'S06R01.txt',\n",
       " 'S06R02.txt',\n",
       " 'S08R01.txt',\n",
       " 'S04R01.txt',\n",
       " 'S01R01.txt',\n",
       " 'S01R02.txt',\n",
       " 'S03R02.txt',\n",
       " 'S03R03.txt',\n",
       " 'S03R01.txt',\n",
       " 'S07R02.txt',\n",
       " 'S07R01.txt',\n",
       " 'S09R01.txt',\n",
       " 'S05R01.txt',\n",
       " 'S05R02.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd7aa36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f1d8e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S10\n",
      "S10R01.txt  is read\t\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R02.txt  is read\t\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "\n",
      "S04\n",
      "S04R01.txt  is read\t\n",
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\tS03R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R03.txt  is read\t\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "\n",
      "S10\n",
      "S10R01.txt  is read\t\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R02.txt  is read\t\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "\n",
      "S04\n",
      "S04R01.txt  is read\t\n",
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\tS03R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R03.txt  is read\t\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "\n",
      "S10\n",
      "S10R01.txt  is read\t\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R02.txt  is read\t\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "\n",
      "S04\n",
      "S04R01.txt  is read\t\n",
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\tS03R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R03.txt  is read\t\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "\n",
      "S10\n",
      "S10R01.txt  is read\t\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R02.txt  is read\t\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "\n",
      "S04\n",
      "S04R01.txt  is read\t\n",
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\tS03R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R03.txt  is read\t\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>A_F</th>\n",
       "      <th>A_V</th>\n",
       "      <th>A_L</th>\n",
       "      <th>L_F</th>\n",
       "      <th>L_V</th>\n",
       "      <th>L_L</th>\n",
       "      <th>T_F</th>\n",
       "      <th>T_V</th>\n",
       "      <th>T_L</th>\n",
       "      <th>Action</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670000</td>\n",
       "      <td>-151</td>\n",
       "      <td>990</td>\n",
       "      <td>267</td>\n",
       "      <td>63</td>\n",
       "      <td>990</td>\n",
       "      <td>80</td>\n",
       "      <td>-9</td>\n",
       "      <td>1019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670015</td>\n",
       "      <td>-151</td>\n",
       "      <td>1000</td>\n",
       "      <td>277</td>\n",
       "      <td>63</td>\n",
       "      <td>981</td>\n",
       "      <td>80</td>\n",
       "      <td>-9</td>\n",
       "      <td>1009</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>S02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670031</td>\n",
       "      <td>-181</td>\n",
       "      <td>1009</td>\n",
       "      <td>247</td>\n",
       "      <td>63</td>\n",
       "      <td>981</td>\n",
       "      <td>70</td>\n",
       "      <td>-9</td>\n",
       "      <td>1019</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>S02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670046</td>\n",
       "      <td>-161</td>\n",
       "      <td>990</td>\n",
       "      <td>237</td>\n",
       "      <td>81</td>\n",
       "      <td>981</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>S02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670062</td>\n",
       "      <td>-151</td>\n",
       "      <td>1000</td>\n",
       "      <td>257</td>\n",
       "      <td>81</td>\n",
       "      <td>981</td>\n",
       "      <td>80</td>\n",
       "      <td>-9</td>\n",
       "      <td>1000</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>S02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298667</th>\n",
       "      <td>1469937</td>\n",
       "      <td>343</td>\n",
       "      <td>1009</td>\n",
       "      <td>118</td>\n",
       "      <td>818</td>\n",
       "      <td>481</td>\n",
       "      <td>-50</td>\n",
       "      <td>864</td>\n",
       "      <td>485</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298668</th>\n",
       "      <td>1469953</td>\n",
       "      <td>313</td>\n",
       "      <td>990</td>\n",
       "      <td>128</td>\n",
       "      <td>818</td>\n",
       "      <td>527</td>\n",
       "      <td>-80</td>\n",
       "      <td>844</td>\n",
       "      <td>476</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298669</th>\n",
       "      <td>1469968</td>\n",
       "      <td>333</td>\n",
       "      <td>1000</td>\n",
       "      <td>108</td>\n",
       "      <td>827</td>\n",
       "      <td>500</td>\n",
       "      <td>-20</td>\n",
       "      <td>864</td>\n",
       "      <td>466</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298670</th>\n",
       "      <td>1469984</td>\n",
       "      <td>323</td>\n",
       "      <td>1039</td>\n",
       "      <td>108</td>\n",
       "      <td>836</td>\n",
       "      <td>500</td>\n",
       "      <td>-40</td>\n",
       "      <td>854</td>\n",
       "      <td>457</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298671</th>\n",
       "      <td>1470000</td>\n",
       "      <td>333</td>\n",
       "      <td>980</td>\n",
       "      <td>168</td>\n",
       "      <td>836</td>\n",
       "      <td>500</td>\n",
       "      <td>-60</td>\n",
       "      <td>873</td>\n",
       "      <td>438</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3298672 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  A_F   A_V  A_L  L_F  L_V  L_L  T_F   T_V  T_L  Action name\n",
       "0         670000 -151   990  267   63  990   80   -9  1019    0       0  S02\n",
       "1         670015 -151  1000  277   63  981   80   -9  1009   58       0  S02\n",
       "2         670031 -181  1009  247   63  981   70   -9  1019   38       0  S02\n",
       "3         670046 -161   990  237   81  981   80    0  1019   48       0  S02\n",
       "4         670062 -151  1000  257   81  981   80   -9  1000   38       0  S02\n",
       "...          ...  ...   ...  ...  ...  ...  ...  ...   ...  ...     ...  ...\n",
       "3298667  1469937  343  1009  118  818  481  -50  864   485  203       0  S05\n",
       "3298668  1469953  313   990  128  818  527  -80  844   476  223       0  S05\n",
       "3298669  1469968  333  1000  108  827  500  -20  864   466  194       0  S05\n",
       "3298670  1469984  323  1039  108  836  500  -40  854   457  233       0  S05\n",
       "3298671  1470000  333   980  168  836  500  -60  873   438  223       0  S05\n",
       "\n",
       "[3298672 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "people = []\n",
    "for person in os.listdir(data_path):\n",
    "    if '.txt' in person:\n",
    "        people.append(person)\n",
    "for window_length in range(1,5):\n",
    "    for person in people:\n",
    "        name = person.split('R')[0]\n",
    "        print (name)\n",
    "        file = data_path+\"/\"+person\n",
    "        temp = pd.read_csv(file,delimiter= \" \", header = None)\n",
    "        print (person,' is read',end = '\\t')\n",
    "        if 2 in temp[max(temp.columns)].unique():\n",
    "            print ('Adding {} to dataset'.format(person),end = '\\t')\n",
    "            temp.columns = ['time','A_F','A_V','A_L','L_F','L_V','L_L','T_F','T_V','T_L','Action']\n",
    "            temp = label_prefog(temp,window_length).reset_index(drop=True)\n",
    "            temp['name'] = name\n",
    "            print ('{} is labelled'.format(person))\n",
    "            dataset = pd.concat([dataset,temp],axis = 0)\n",
    "\n",
    "        print ('')\n",
    "    dataset.reset_index(drop =True,inplace=True)\n",
    "    to_path = path + \"/raw_labelled\"\n",
    "    to_name = to_path +\"/win_\"+str(window_length)+\".csv\"\n",
    "\n",
    "    dataset.to_csv(to_name,index = False)\n",
    "\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4917c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(act,window_length,dataframe):\n",
    "    \n",
    "  indices = list(dataframe[dataframe.Action == act].index)\n",
    "  groups = []\n",
    "  temp = []\n",
    "  group_count = 0\n",
    "  for i in range(len(indices)):\n",
    "    if i == len(indices)-1:\n",
    "      temp.append(indices[i])\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "      break\n",
    "    temp.append(indices[i])\n",
    "    if indices[i]+1 != indices[i+1]: \n",
    "      group_count+=1\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "\n",
    "  fs = 64\n",
    "  window_length = 1\n",
    "  # window_length = window_length*fs\n",
    "\n",
    "  final_dataframe = pd.DataFrame()\n",
    "  for i in groups: \n",
    "    required = math.floor(len(i)/(window_length*fs))\n",
    "    \n",
    "    req_index = i[0:(required*fs)]\n",
    "    \n",
    "    final_dataframe = pd.concat([final_dataframe,dataframe.iloc[req_index,:]],axis = 0)\n",
    "  return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd0f4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_length in range(1,5):\n",
    "  \n",
    "#   path = os.getcwd()+\"/dataset_fog_release/dataset\"\n",
    "  name = path+\"/raw_labelled/win_\"+str(window_length)+\".csv\"\n",
    "  dataframe = pd.read_csv(name)\n",
    "\n",
    "  activities = []\n",
    "  for act in range(3):\n",
    "    activities.append(create_window(act,window_length,dataframe))\n",
    "  to_write = pd.concat(activities,axis = 0)\n",
    "  to_path = path + \"/windows\"+\"/windowed_\"+str(window_length)+\".csv\"\n",
    "  to_write.to_csv(to_path,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d44966cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_F A_V A_L L_F L_V L_L T_F T_V T_L A_F A_V A_L L_F L_V L_L T_F T_V T_L A_F A_V A_L L_F L_V L_L T_F T_V T_L A_F A_V A_L L_F L_V L_L T_F T_V T_L "
     ]
    }
   ],
   "source": [
    "fs = 64\n",
    "for window_length in range(1,5):\n",
    "  w = window_length*fs\n",
    "  FE_path = path + \"/windows/windowed_\"\n",
    "  name = FE_path + str(window_length) + \".csv\"\n",
    "  dataframe = pd.read_csv(name)\n",
    "\n",
    "  df = dataframe.drop(columns=['time','Action','name'])\n",
    "  stat = pd.DataFrame()\n",
    "\n",
    "\n",
    "  col= list(df.columns)\n",
    "  for s in col:\n",
    "    print (s,end=\" \")\n",
    "    mn =[]\n",
    "    var = []\n",
    "    std = []\n",
    "    mav = []\n",
    "    rms =[]\n",
    "    for i in range(0,len(df),w):\n",
    "        mn_  = np.mean(df[s].iloc[i:i+w])\n",
    "        var_  = np.var(df[s].iloc[i:i+w])\n",
    "        std_  = np.std(df[s].iloc[i:i+w])\n",
    "        mav_  = np.mean(abs(df[s].iloc[i:i+w]))\n",
    "        rms_  = np.sqrt(np.mean((df[s].iloc[i:i+w])**2))\n",
    "\n",
    "        mn.append(mn_)\n",
    "        var.append(var_)\n",
    "        std.append(std_)\n",
    "        mav.append(mav_)\n",
    "        rms.append(rms_)\n",
    "\n",
    "    stat['mean_'+s] = mn\n",
    "    stat['var_'+s] = var\n",
    "    stat['std_'+s] = std\n",
    "    stat['rms_'+s] = rms\n",
    "    stat['mav_'+s] = mav\n",
    "\n",
    "\n",
    "  stat.shape\n",
    "\n",
    "\n",
    "  import copy\n",
    "  stat1 = copy.copy(stat)\n",
    "  stat1['w'] = dataframe['Action'].iloc[[x for x in range(0,len(dataframe),w)]].to_list()\n",
    "  order = ['w']\n",
    "  order += stat1.columns.to_list()[:-1]\n",
    "  stat1 = stat1[order]\n",
    "  stat1.columns\n",
    "  col = stat1.columns.to_list()\n",
    "  col[0] = 0\n",
    "  stat1.columns = col\n",
    "  feature_name = path + \"/features/time_\"+str(window_length)+\".csv\"\n",
    "  stat1.to_csv(feature_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4599061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze and power done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/v2__c9c92wvg9t0j94btmdzw0000gn/T/ipykernel_79894/3882232058.py:76: RuntimeWarning: invalid value encountered in true_divide\n",
      "  p_norm = Pxx_den/sum(Pxx_den)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze and power done\n",
      "Freeze and power done\n",
      "Freeze and power done\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "#window_length = 3\n",
    "fs = 64\n",
    "for window_length in range(1,5):\n",
    "  w = window_length*fs\n",
    "  FE_path = path + \"/windows/windowed_\"\n",
    "  name = FE_path + str(window_length) + \".csv\"\n",
    "  dataframe = pd.read_csv(name)\n",
    "\n",
    "  df = dataframe.drop(columns=['time','Action','name'])\n",
    "\n",
    "  col= list(df.columns)\n",
    "\n",
    "  order=5\n",
    "\n",
    "  fi=pd.DataFrame()\n",
    "\n",
    "  power = pd.DataFrame()\n",
    "  bands = {'locomotor' :(0.5,3),'freeze' :(3,8)}\n",
    "\n",
    "  for s in col:\n",
    "      xtemp = []\n",
    "      xtemp1 = []\n",
    "      for i in range(0,len(df),w):\n",
    "          nyq=0.5*fs\n",
    "\n",
    "          #locomotor band 0.5-3hz\n",
    "          loc_low= 0.5/nyq\n",
    "          loc_high=3/nyq\n",
    "\n",
    "          #clipping off band from the window\n",
    "          b, a = butter(order, [loc_low, loc_high], btype='band')\n",
    "          y=lfilter(b,a,df[s].iloc[i:i+w])\n",
    "\n",
    "          #total power in locomotor band\n",
    "          e1=sum([x**2 for x in y])\n",
    "\n",
    "          #freeze band 3-8hz\n",
    "          frez_low= 3/nyq\n",
    "          frez_high=8/nyq\n",
    "\n",
    "          #clipping off band from the window\n",
    "          b1, a1 = butter(order, [frez_low, frez_high], btype='band')\n",
    "          y1=lfilter(b1,a1,df[s].iloc[i:i+w])\n",
    "          #total power in locomotor band\n",
    "          e2=sum([x**2 for x in y1])\n",
    "\n",
    "          FI=e2/e1\n",
    "          POW=e2+e1\n",
    "          xtemp.append(FI)\n",
    "          xtemp1.append(POW)\n",
    "      fi['FI'+s] = xtemp\n",
    "      power['P'+s] = xtemp1\n",
    "  print (\"Freeze and power done\")\n",
    "\n",
    "\n",
    "  w = window_length*fs\n",
    "  E=[]\n",
    "  for i in range(0,len(df),w):\n",
    "    energy = np.sum((df.iloc[i:i+w,:])**2)\n",
    "    E.append(energy)\n",
    "  E = pd.DataFrame(E)\n",
    "  E.columns = [\"EN_\" + x for x in df.columns]\n",
    "\n",
    "  #Entropy\n",
    "  from scipy.signal import periodogram\n",
    "\n",
    "  peak_f = pd.DataFrame()\n",
    "  PSE = pd.DataFrame()\n",
    "  for s in col:\n",
    "    peakF = []\n",
    "    pse = []\n",
    "    for i in range(0,len(df),w):\n",
    "        f,Pxx_den = periodogram(df[s].iloc[i:i+w],fs)\n",
    "        p_norm = Pxx_den/sum(Pxx_den)\n",
    "        p_norm = list(filter(lambda a: a != 0, p_norm))\n",
    "        pse.append(-(np.sum(p_norm*np.log(p_norm))))\n",
    "        peak = (fs/w)*max(Pxx_den)\n",
    "        peakF.append(peak)\n",
    "    PSE['ENt_'+s] = pse\n",
    "    peak_f['peak_'+s] = peakF\n",
    "  PSE.fillna(0,inplace = True)\n",
    "\n",
    "\n",
    "  freq = pd.concat([fi,power,E,PSE,peak_f],axis = 1)\n",
    "\n",
    "  feature_name = path + \"/features/freq_\"+str(window_length)+\".csv\"\n",
    "  freq.to_csv(feature_name, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "627968a1",
   "metadata": {},
   "source": [
    "**ML MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6838ed83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_F</th>\n",
       "      <th>A_V</th>\n",
       "      <th>A_L</th>\n",
       "      <th>L_F</th>\n",
       "      <th>L_V</th>\n",
       "      <th>L_L</th>\n",
       "      <th>T_F</th>\n",
       "      <th>T_V</th>\n",
       "      <th>T_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-151</td>\n",
       "      <td>990</td>\n",
       "      <td>267</td>\n",
       "      <td>63</td>\n",
       "      <td>990</td>\n",
       "      <td>80</td>\n",
       "      <td>-9</td>\n",
       "      <td>1019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-151</td>\n",
       "      <td>1000</td>\n",
       "      <td>277</td>\n",
       "      <td>63</td>\n",
       "      <td>981</td>\n",
       "      <td>80</td>\n",
       "      <td>-9</td>\n",
       "      <td>1009</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-181</td>\n",
       "      <td>1009</td>\n",
       "      <td>247</td>\n",
       "      <td>63</td>\n",
       "      <td>981</td>\n",
       "      <td>70</td>\n",
       "      <td>-9</td>\n",
       "      <td>1019</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-161</td>\n",
       "      <td>990</td>\n",
       "      <td>237</td>\n",
       "      <td>81</td>\n",
       "      <td>981</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-151</td>\n",
       "      <td>1000</td>\n",
       "      <td>257</td>\n",
       "      <td>81</td>\n",
       "      <td>981</td>\n",
       "      <td>80</td>\n",
       "      <td>-9</td>\n",
       "      <td>1000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243707</th>\n",
       "      <td>-383</td>\n",
       "      <td>794</td>\n",
       "      <td>277</td>\n",
       "      <td>-63</td>\n",
       "      <td>879</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>1038</td>\n",
       "      <td>-87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243708</th>\n",
       "      <td>-414</td>\n",
       "      <td>725</td>\n",
       "      <td>267</td>\n",
       "      <td>-118</td>\n",
       "      <td>888</td>\n",
       "      <td>101</td>\n",
       "      <td>87</td>\n",
       "      <td>1057</td>\n",
       "      <td>-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243709</th>\n",
       "      <td>-252</td>\n",
       "      <td>696</td>\n",
       "      <td>247</td>\n",
       "      <td>-181</td>\n",
       "      <td>879</td>\n",
       "      <td>101</td>\n",
       "      <td>87</td>\n",
       "      <td>1057</td>\n",
       "      <td>-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243710</th>\n",
       "      <td>-40</td>\n",
       "      <td>627</td>\n",
       "      <td>168</td>\n",
       "      <td>-209</td>\n",
       "      <td>851</td>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>1057</td>\n",
       "      <td>-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243711</th>\n",
       "      <td>40</td>\n",
       "      <td>617</td>\n",
       "      <td>188</td>\n",
       "      <td>-218</td>\n",
       "      <td>842</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>1057</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3243712 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A_F   A_V  A_L  L_F  L_V  L_L  T_F   T_V  T_L\n",
       "0       -151   990  267   63  990   80   -9  1019    0\n",
       "1       -151  1000  277   63  981   80   -9  1009   58\n",
       "2       -181  1009  247   63  981   70   -9  1019   38\n",
       "3       -161   990  237   81  981   80    0  1019   48\n",
       "4       -151  1000  257   81  981   80   -9  1000   38\n",
       "...      ...   ...  ...  ...  ...  ...  ...   ...  ...\n",
       "3243707 -383   794  277  -63  879   80   58  1038  -87\n",
       "3243708 -414   725  267 -118  888  101   87  1057  -48\n",
       "3243709 -252   696  247 -181  879  101   87  1057  -48\n",
       "3243710  -40   627  168 -209  851   40   77  1057  -48\n",
       "3243711   40   617  188 -218  842   80   77  1057  -58\n",
       "\n",
       "[3243712 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe0d9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    a = df.drop(columns = ['0'])\n",
    "    for i in df.columns.to_list():\n",
    "        mean = df[i].mean()\n",
    "        std = df[i].std()\n",
    "        df[i] = (df[i]-mean)/std\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44fb850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe(model,X_train,y_train):\n",
    "    from sklearn.feature_selection import RFE\n",
    "    selector = RFE(model,60,1,1)\n",
    "    selector.fit(X_train,y_train)\n",
    "    selector.ranking_\n",
    "    y_p = selector.predict(X_test)\n",
    "    print (confusion_matrix(y_test,y_p))\n",
    "    print (classification_report(y_test,y_p,digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33a4d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsize(model):\n",
    "    p = pickle.dumps(model)\n",
    "    return sys.getsizeof(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56067036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfeatures(model,X_train,y_train):\n",
    "    from sklearn.feature_selection import RFE\n",
    "    model = DecisionTreeClassifier()\n",
    "    selector = RFE(model,60,1)\n",
    "    selector.fit(X_train,y_train)\n",
    "    col = []\n",
    "    for i in range(len(selector.ranking_)):\n",
    "        if selector.ranking_[i] == 1:\n",
    "            col.append(X_train.columns[i])\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67b46557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12671, 46) (12671, 45)\n",
      "0    10488\n",
      "1     1594\n",
      "2      589\n",
      "Name: 0, dtype: int64\n",
      "0    10488\n",
      "1     1594\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "featurePath = path + '/features'\n",
    "windowLength = 1\n",
    "fs = 64\n",
    "    \n",
    "readTime = featurePath +\"/time_\" +str(window_length)+\".csv\"\n",
    "readFreq = featurePath + \"/freq_\"+str(window_length)+\".csv\"\n",
    "timeDom = pd.read_csv(readTime)\n",
    "freqDom = pd.read_csv(readFreq)\n",
    "\n",
    "print (timeDom.shape,freqDom.shape)\n",
    "    \n",
    "df = pd.concat([timeDom,freqDom],axis = 1)\n",
    "    \n",
    "print (df['0'].value_counts())\n",
    "    \n",
    "df = df[df['0'] != 2]\n",
    "\n",
    "print (df['0'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57dfcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2c5542c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m X_resampled, y_resampled \u001b[39m=\u001b[39m SMOTE()\u001b[39m.\u001b[39;49mfit_resample(X,y)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m (X_resampled\u001b[39m.\u001b[39mshape,y_resampled\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m X_train,X_test,y_train,y_test \u001b[39m=\u001b[39m train_test_split(X_resampled,y_resampled, train_size \u001b[39m=\u001b[39m \u001b[39m0.7\u001b[39m, stratify \u001b[39m=\u001b[39m y_resampled)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/imblearn/base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/imblearn/base.py:80\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_resample\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     check_classification_targets(y)\n\u001b[1;32m     81\u001b[0m     arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m     82\u001b[0m     X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/multiclass.py:197\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    189\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y)\n\u001b[1;32m    190\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    191\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    192\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    196\u001b[0m ]:\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X = df.drop(columns = [\"0\"])\n",
    "y = df['0']\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X,y)\n",
    "\n",
    "print (X_resampled.shape,y_resampled.shape)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled, train_size = 0.7, stratify = y_resampled)\n",
    "\n",
    "print (X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75a9a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.0.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e4de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
